{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import IPython.display as ipd\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establece la ruta del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta=\"/Users/andavaro/Desktop/Andrès/UBA/TrabajoDeGradoCEIA/VENV_Python/Tesis_IA/Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory will be: /Users/andavaro/Desktop/Andrès/UBA/TrabajoDeGradoCEIA/VENV_Python/Tesis_IA/Dataset/\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path(ruta)\n",
    "os.chdir(ruta)\n",
    "default_dir = os.getcwd()\n",
    "print(f'Data directory will be: {ruta}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa los nombres de las carpetas que contiene el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Labels: 3\n",
      "Label Names: ['VT', 'Copia de VT 2', 'Copia de VT']\n"
     ]
    }
   ],
   "source": [
    "labels = [name for name in os.listdir('.') if os.path.isdir(name)]\n",
    "# back to default directory\n",
    "os.chdir(default_dir)\n",
    "print(f'Total Labels: {len(labels)}')\n",
    "print(f'Label Names: {labels}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula el total de muestras que contiene el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total examples: 30\n"
     ]
    }
   ],
   "source": [
    "filenames = tf.io.gfile.glob(str(default_dir) + '/*/*')\n",
    "num_samples = len(filenames)\n",
    "print('Number of total examples:', num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VT\n",
      "Copia de VT 2\n",
      "Copia de VT\n"
     ]
    }
   ],
   "source": [
    "for l in labels:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_files(main_path: str, label:str):\n",
    "\n",
    "    dataset = []\n",
    "    \n",
    "    for l in labels:\n",
    "        \n",
    "        dataset_l = []\n",
    "        path = main_path+l\n",
    "        walker = sorted(str(p) for p in Path(path).glob(f'*.csv'))\n",
    "\n",
    "        for i, file_path in enumerate(walker):\n",
    "            path, filename = os.path.split(file_path)\n",
    "            \n",
    "            file = pd.read_csv(path+'/'+filename)\n",
    "            mean=np.mean(file.Señal)\n",
    "            data = tf.convert_to_tensor(file.Señal-mean, dtype=tf.float32)\n",
    "            \n",
    "            dataset_l.append([data, l])\n",
    "\n",
    "        dataset.append(dataset_l)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de datasets: 3\n",
      "Tamaño del dataset VT :  5\n",
      "Tamaño del dataset Copia de VT 2 :  5\n",
      "Tamaño del dataset Copia de VT :  5\n"
     ]
    }
   ],
   "source": [
    "trainset = load_audio_files(ruta, labels)\n",
    "print(f'Número de datasets: {len(trainset)}')\n",
    "for ds in range(len(trainset)):\n",
    "    print('Tamaño del dataset', trainset[ds][0][1], ': ', len(trainset[ds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform, ns=300, sol=0.5):\n",
    "    '''\n",
    "    waveform = señal\n",
    "    ns = número de muestras por sección\n",
    "    sol = porcentaje de solapamiento\n",
    "    '''\n",
    "    frame_length = round(waveform.shape[0] / (ns-(ns-1)*sol))\n",
    "    frame_step = round(sol*frame_length)\n",
    "    \n",
    "    #frame_length = 255\n",
    "    #frame_step = 128\n",
    "    # Padding for files with less than 16000 samples\n",
    "    zero_padding = tf.zeros([waveform.shape[0]] - tf.shape(waveform), dtype=tf.float32)\n",
    "\n",
    "    # Concatenate audio with padding so that all audio clips will be of the same length\n",
    "    waveform = tf.cast(waveform, tf.float32)\n",
    "    equal_length_waveform = tf.concat([waveform, zero_padding], 0)\n",
    "    \n",
    "    # Option 1: Use tfio to get the spectrogram\n",
    "    #spect = tfio.audio.spectrogram(input=equal_length_waveform, nfft=frame_length, window=frame_length, stride=frame_step)\n",
    "    \n",
    "    # Option 2: Use tf.signal processing to get the Short-time Fourier transform (stft)\n",
    "    spectro = tf.signal.stft(equal_length_waveform, frame_length=frame_length, frame_step=frame_step, window_fn=tf.signal.hamming_window)\n",
    "    spectrogram = tf.abs(spectro)\n",
    "\n",
    "    return spectrogram#, spect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images(dataset, ds_dir, label_dir):\n",
    "    # make directory\n",
    "    for l in range(len(label_dir)):\n",
    "        directory = f'{ds_dir}{label_dir[l]}/'\n",
    "\n",
    "        os.makedirs(directory, mode=0o777, exist_ok=True)\n",
    "\n",
    "        for i, data in enumerate(dataset[l]):\n",
    "\n",
    "            waveform = data[0]\n",
    "            spectrogram= get_spectrogram(waveform)\n",
    "\n",
    "            # Split test and train images by 30%\n",
    "            \n",
    "            plt.imsave(f'{ds_dir}{label_dir[l]}/spec_img{i}.png', spectrogram.numpy().T)\n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 300\n",
    "sol = 0.7\n",
    "lf = 0\n",
    "uf = 250\n",
    "create_images(trainset, ruta, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tesis_IA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
